{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5wi_r4gyzFr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "CHANNEL_N = 16        # Number of CA state channels\n",
        "TARGET_SIZE = 32\n",
        "BATCH_SIZE = 2\n",
        "POOL_SIZE = 256 # 512 for Colab Pro, 1024 for Colab Pro+\n",
        "CELL_FIRE_RATE = 0.75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCbPFbI_zosW",
        "outputId": "65990200-261d-4460-cbf8-7107dcc3b0db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 3, 3, 3, 64)       1728      \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 3, 3, 3, 160)      10400     \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 3, 3, 3, 16)       2576      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,704\n",
            "Trainable params: 12,976\n",
            "Non-trainable params: 1,728\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv3D\n",
        "\n",
        "def to_rgba(x):\n",
        "    return x[..., :4]\n",
        "\n",
        "def to_alpha(x):\n",
        "    return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "    # assume rgb premultiplied by alpha\n",
        "    rgb, a = x[..., :3], to_alpha(x)\n",
        "    return 1.0-a+rgb\n",
        "\n",
        "def get_living_mask(x):\n",
        "    alpha = x[:, :, :, :, 3:4]\n",
        "    return tf.nn.max_pool3d(alpha, 3, [1, 1, 1, 1, 1], 'SAME') > 0.1\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "    x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "    x[:, size//2, size//2, size//2, 3:] = 1.0\n",
        "    return x\n",
        "\n",
        "class CAModel3D(tf.keras.Model):\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "\n",
        "    perc = Conv3D(64, 3, activation=None, groups=self.channel_n, \n",
        "                 padding=\"SAME\", use_bias=False, trainable=False)\n",
        "    \n",
        "    self.dmodel = tf.keras.Sequential([\n",
        "          perc,\n",
        "          Conv3D(160, 1, activation=tf.nn.relu),\n",
        "          Conv3D(self.channel_n, 1, activation=None,\n",
        "              kernel_initializer=tf.zeros_initializer),\n",
        "    ])\n",
        "    \n",
        "    self.build((None, 3, 3, 3, channel_n))\n",
        "        \n",
        "    identify = np.zeros((3, 3, 3))\n",
        "    identify[1, 1, 1] = 1\n",
        "    # 3D Sobel filters\n",
        "    dx = np.array([1, 2, 1])[None, None, :] * np.outer([1, 2, 1], [-1, 0, 1])[:, :, None] / 32\n",
        "    dy = np.array([1, 2, 1])[None, None, :] * np.outer([1, 2, 1], [-1, 0, 1]).T[:, :, None] / 32\n",
        "    dz = (np.array([1, 2, 1])[None, None, :] * np.outer([1, 2, 1], [-1, 0, 1]).T[:, :, None]).T / 32\n",
        "\n",
        "    kernel = np.stack([identify, dx, dy, dz], -1)[:, :, :, None, :]\n",
        "    kernel = np.repeat([kernel], repeats=CHANNEL_N, axis=-1)\n",
        "    perc.set_weights(kernel)\n",
        "    \n",
        "    self.dmodel.layers[0].trainable = False\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    pre_life_mask = get_living_mask(x)\n",
        "    dx = self.dmodel(x)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    post_life_mask = get_living_mask(x)\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel3D().dmodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDX5HL7VLd0z"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeWf6HeTe8kM"
      },
      "outputs": [],
      "source": [
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.array(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k).setflags(write=1)\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "@tf.function\n",
        "def make_circle_masks(n, h, w, d):\n",
        "  x = tf.linspace(-1.0, 1.0, w)[None, :, None, None]\n",
        "  y = tf.linspace(-1.0, 1.0, h)[None, None, :, None]\n",
        "  z = tf.linspace(-1.0, 1.0, d)[None, None, None, :]\n",
        "  center = tf.random.uniform([3, n, 1, 1, 1], -0.5, 0.5)\n",
        "  r = tf.random.uniform([n, 1, 1, 1], 0.1, 0.3)\n",
        "  x, y, z = (x - center[0])/r, (y - center[1])/r, (z - center[2])/r\n",
        "  mask = tf.cast(x*x+y*y+z*z < 1.0, tf.float32)\n",
        "  return mask\n",
        "\n",
        "def export_model(ca, base_fn):\n",
        "  ca.save_weights(base_fn)\n",
        "\n",
        "  cf = ca.call.get_concrete_function(\n",
        "      x=tf.TensorSpec([None, None, None, None, CHANNEL_N]),\n",
        "      fire_rate=tf.constant(0.5),\n",
        "      angle=tf.constant(0.0),\n",
        "      step_size=tf.constant(1.0))\n",
        "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
        "  graph_def = cf.graph.as_graph_def()\n",
        "  graph_json = MessageToDict(graph_def)\n",
        "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
        "  model_json = {\n",
        "      'format': 'graph-model',\n",
        "      'modelTopology': graph_json,\n",
        "      'weightsManifest': [],\n",
        "  }\n",
        "  with open(base_fn+'.json', 'w') as f:\n",
        "    json.dump(model_json, f)\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  pl.figure(figsize=(10, 4))\n",
        "  pl.title('Loss history (log10)')\n",
        "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
        "  pl.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "2U8Me6-m8fFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ZgJcCDWbzM",
        "outputId": "59c22389-473b-4579-9831-f90432aefdcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCyMU-zX_CQY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_3d(arr):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    #u = np.moveaxis(arr, (0, 1), (0, 1))\n",
        "    u=arr\n",
        "    m = ax.voxels((u[:, :, :, 3] > 0.1), \n",
        "                  facecolors=np.clip(u[:, :, :, :4], 0, 1))\n",
        "    clear_output()\n",
        "    plt.show()\n",
        "\n",
        "p = TARGET_SIZE\n",
        "\n",
        "\n",
        "with open('filter_piece.json','r') as f:\n",
        "    cat3_data = json.loads(f.read())\n",
        "vox = np.array(cat3_data)\n",
        "\n",
        "targets = [vox,vox]\n",
        "\n",
        "plot_3d(targets[0])\n",
        "\n",
        "\n",
        "def pad_tgt(tgt):\n",
        "    px = (p - tgt.shape[0]) // 2\n",
        "    py = (p - tgt.shape[1]) // 2\n",
        "    pz = (p - tgt.shape[2]) // 2\n",
        "    return tf.pad(tgt, [\n",
        "        (px, px + (p - tgt.shape[0] - 2 * px)), \n",
        "        (py, py + (p - tgt.shape[1] - 2 * py)), \n",
        "        (pz, pz + (p - tgt.shape[2] - 2 * pz)), (0, 0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak5rBmbxmHV7"
      },
      "outputs": [],
      "source": [
        "pad_targets = [tf.cast(pad_tgt(target_img), tf.float32) \n",
        "for target_img in targets]\n",
        "\n",
        "print(pad_targets[0].shape)\n",
        "print(pad_targets[1].shape)\n",
        "\n",
        "\n",
        "#plot_3d(pad_targets[0])\n",
        "h, w, d = pad_targets[0].shape[:3]\n",
        "seed = np.zeros([len(targets), h, w, d, CHANNEL_N], np.float32)\n",
        "\n",
        "\n",
        "# define seed here\n",
        "\n",
        "seed[0,15,15,15,3:]=1.0\n",
        "seed[1,15,15,15,3:]=1.0\n",
        "\n",
        "# show seed\n",
        "plot_3d(seed[0,:,:,:,:4])\n",
        "plot_3d(seed[1,:,:,:,:4])\n",
        "\n",
        "def loss_f(x, target):\n",
        "    return tf.reduce_mean(tf.square(to_rgba(x) - target), \n",
        "                          [-2, -3, -4, -1])\n",
        "\n",
        "ca = CAModel3D()\n",
        "loss_log = []\n",
        "\n",
        "lr = 1e-3\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000], [lr, lr*0.1])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "loss0 = loss_f(seed[0], pad_targets[0]).numpy()\n",
        "\n",
        "inp = tf.cast(np.repeat(seed, POOL_SIZE//len(targets), 0), tf.float32)\n",
        "tgt = tf.repeat(pad_targets, POOL_SIZE//len(targets), 0)\n",
        "\n",
        "pool = SamplePool(x=inp, y=tgt)\n",
        "\n",
        "#plot_3d(np.array(pad_targets[1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stmr82kObBed"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_62TRf4VpgR"
      },
      "outputs": [],
      "source": [
        "def batch_3d_viz(x, x0):\n",
        "    fig = plt.figure(figsize=plt.figaspect(0.35)*1.5)\n",
        "    ax = [fig.add_subplot(2, BATCH_SIZE, i, projection='3d') \n",
        "          for i in range(1, 2 * BATCH_SIZE + 1)]\n",
        "    for i in range(BATCH_SIZE):\n",
        "        u = np.moveaxis(x0[i], (0, 1), (0, 1))\n",
        "        ax[i].set_axis_off()\n",
        "        ax[i].voxels((u[:, :, :, 3] > 0.1), \n",
        "                     facecolors=np.clip(u[:, :, :, :4], 0, 1))\n",
        "    for i in range(BATCH_SIZE):\n",
        "        u = np.moveaxis(x[i].numpy(), (0, 1), (0, 1))\n",
        "        ax[BATCH_SIZE + i].set_axis_off()\n",
        "        ax[BATCH_SIZE + i].voxels((u[:, :, :, 3] > 0.1), \n",
        "                                  facecolors=np.clip(u[:, :, :, :4], 0, 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "7PLnOOZ685bR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCSaMnXpshq_"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    iter_n = tf.random.uniform([], 64, 96, tf.int32)\n",
        "    with tf.GradientTape() as g:\n",
        "        for i in tf.range(iter_n):\n",
        "            x = ca(x)\n",
        "        loss = tf.reduce_mean(loss_f(x, y))\n",
        "    grads = g.gradient(loss, ca.weights)\n",
        "    grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "    # Hack to not train the first layer (Sobel filters)\n",
        "    # because apparently setting .trainable = False isn't enough\n",
        "    trainer.apply_gradients(zip(grads[1:], ca.weights[1:])) \n",
        "    return x, y, loss\n",
        "\n",
        "# ca.save_weights('./catheadtest.h5')\n",
        "\n",
        "for i in range(5000):\n",
        "    batch = pool.sample(BATCH_SIZE)\n",
        "    x0 = batch.x\n",
        "    y0 = batch.y\n",
        "    # print(x0.shape) == (4, 32, 32, 32, 16)\n",
        "    # print(y0.shape) == (4, 32, 32, 32, 4)\n",
        "\n",
        "    loss_rank = loss_f(x0, y0).numpy().argsort()[::-1]\n",
        "    \n",
        "    # print(loss_rank.shape) == (4,) might be the loss of 4 targets\n",
        "    \n",
        "    \n",
        "    x0 = x0[loss_rank]\n",
        "    y0 = y0[loss_rank]\n",
        "    # print(x0.shape) == (4, 32, 32, 32, 16)\n",
        "    # print(y0.shape) == (4, 32, 32, 32, 4)\n",
        "\n",
        "    simple = np.random.choice(range(len(targets)), size=2) # two random number in targets\n",
        "\n",
        "    # print(x0[:2].shape) == (2, 32, 32, 32, 16)\n",
        "    # print(seed[simple].shape) == (2, 32, 32, 32, 16)\n",
        "    x0[:2] = seed[simple]\n",
        "    \n",
        "    # remained to be figure out\n",
        "    for n, u in enumerate(simple):  \n",
        "        y0[n] = pad_targets[u]\n",
        "        \n",
        "        \n",
        "    # print(x0.shape) == (4, 32, 32, 32, 16)\n",
        "    # print(y0.shape) == (4, 32, 32, 32, 4)\n",
        "\n",
        "    \n",
        "    x, y, loss = train_step(x0, y0)\n",
        "    \n",
        "    # print(x.shape) == (4, 32, 32, 32, 16)\n",
        "    # print(y.shape) == (4, 32, 32, 32, 4)\n",
        "\n",
        "    step_i = len(loss_log)\n",
        "    loss_log.append(loss.numpy())\n",
        "    #batch_3d_viz(x, x0)\n",
        "\n",
        "    if step_i%100 == 0:\n",
        "      clear_output()\n",
        "      plot_loss(loss_log)\n",
        "      #export_model(ca, 'train_log/%04d'%step_i)\n",
        "      # plot_3d(np.array(x[0,:,:,:,:4]))\n",
        "      # plot_3d(np.array(x[1,:,:,:,:4]))\n",
        "      # batch_3d_viz(x, x0)\n",
        "      \n",
        "\n",
        "    if step_i%200 == 0:\n",
        "      batch_3d_viz(x, x0)\n",
        "      ca.save_weights('./drive/MyDrive/filter_piece.h5')\n",
        "      pass\n",
        "    \n",
        "\n",
        "    print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), \n",
        "                                            np.log10(loss)), end='')\n",
        "    \n",
        "    \n",
        "ca.save_weights('./filter_piecce.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read from trained models"
      ],
      "metadata": {
        "id": "ywtEfRAF88Q-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqCjP0fDTCAU"
      },
      "outputs": [],
      "source": [
        "new_model = CAModel3D()\n",
        "new_model.load_weights('./test.h5')\n",
        "def plot_3d(arr,i):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    u = arr\n",
        "    m = ax.voxels((u[:, :, :, 3] > 0.1), facecolors=np.clip(u[:, :, :, :4], 0, 1))\n",
        "    clear_output()\n",
        "    plt.show()\n",
        "\n",
        "s=32\n",
        "h=s\n",
        "w=s\n",
        "d=s\n",
        "seed = np.zeros([4, s, s, s, 16])\n",
        "seed[0, h//2, w//2 , d//2, 3:] = 1.0\n",
        "\n",
        "plot_3d()\n",
        "\n",
        "seed=new_model(seed)\n",
        "# plot_3d(seed[0],0)\n",
        "\n",
        "for i in range(200):\n",
        "  print(i)\n",
        "  seed = new_model(seed)\n",
        "  # print(seed[0])\n",
        "  # plot_3d(seed[0],i)\n",
        "\n",
        "# with open('output.json','w') as f:\n",
        "#   data = json.dumps(seed[0].numpy().tolist())\n",
        "#   f.write(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rSkOXOo3l4i5"
      },
      "outputs": [],
      "source": [
        "new_model = CAModel3D()\n",
        "new_model.load_weights('drive/MyDrive/hytest_doubleseed.h5')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_3d(arr,i):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    u = np.moveaxis(arr, (0, 1), (0, 1))\n",
        "    m = ax.voxels((u[:, :, :, 3] > 0.1), facecolors=np.clip(u[:, :, :, :4], 0, 1))\n",
        "    plt.savefig('./fig/'+str(i)+'.png')\n",
        "    clear_output()\n",
        "    plt.show()\n",
        "\n",
        "# with open('drive/Mydrive/cat3.json','r') as f:\n",
        "#     cat3_data = json.loads(f.read())\n",
        "# cat3 = np.array(cat3_data)\n",
        "\n",
        "# #plot_3d(cat3,0)\n",
        "\n",
        "# print(cat3.shape)\n",
        "# print(seed[0].shape)\n",
        "\n",
        "s=32\n",
        "h=s\n",
        "w=s\n",
        "d=s\n",
        "seed = np.zeros([4, s, s, s, 16])\n",
        "\n",
        "\n",
        "\n",
        "# defind seed down here\n",
        "\n",
        "\n",
        "seed[0, 15, 12, 11, 3:] = 1.0\n",
        "seed[0, 15, 13, 11, 3:] = 1.0\n",
        "seed[0, 15, 14, 11, 3:] = 1.0\n",
        "seed[0, 15, 15, 11, 3:] = 1.0\n",
        "seed[0, 15, 16, 11, 3:] = 1.0\n",
        "\n",
        "seed[0, 15, 12, 18, 3:] = 1.0\n",
        "seed[0, 15, 13, 18, 3:] = 1.0\n",
        "seed[0, 15, 14, 18, 3:] = 1.0\n",
        "seed[0, 15, 15, 18, 3:] = 1.0\n",
        "seed[0, 15, 16, 18, 3:] = 1.0\n",
        "\n",
        "\n",
        "\n",
        "seed=new_model(seed)\n",
        "plot_3d(seed[0],0)\n",
        "\n",
        "for i in range(95):\n",
        "  print(i)\n",
        "  seed = new_model(seed)\n",
        "  #print(seed[0])\n",
        "  plot_3d(seed[0],i)\n",
        "\n",
        "# with open('output.json','w') as f:\n",
        "#   data = json.dumps(seed[0].numpy().tolist())\n",
        "#   f.write(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gif Generator"
      ],
      "metadata": {
        "id": "nJ-3D6f89LOp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLBMTQ-UJ-DL"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def imgs2gif(imgPaths, saveName, duration=None, loop=0, fps=None):\n",
        "    \"\"\"\n",
        "    :param duration: gap between frames. counted in second\n",
        "    :param loop: 播放次数（在不同的播放器上有所区别）， 0代表循环播放\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if fps:\n",
        "        duration = 1 / fps\n",
        "    images = [imageio.imread(str(img_path)) for img_path in imgPaths]\n",
        "    imageio.mimsave(saveName, images, \"gif\", duration=duration, loop=loop)\n",
        "\n",
        "\n",
        "# pathlist = Path(r\"G:\\img\").glob(\"*.jpg\")\n",
        "\n",
        "p_lis = []\n",
        "for i in range(95):\n",
        "  p_lis.append('./fig/'+str(i)+'.png')\n",
        "\n",
        "# for n, p in enumerate(pathlist):\n",
        "#     if n % 5 == 0:\n",
        "#         p_lis.append(p)\n",
        "\n",
        "imgs2gif(p_lis, \"hy_cat13_4.gif\", 0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "model_gen",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}